# ğŸŒ™ SynthÃ©tiseur de RÃªves

Une application web moderne et impressionnante qui transforme vos rÃªves racontÃ©s en images visuelles grÃ¢ce Ã  l'intelligence artificielle.

## âœ¨ FonctionnalitÃ©s

- **ğŸ¤ Enregistrement Audio** : Upload de fichiers audio (.wav/.mp3) pour raconter vos rÃªves
- **ğŸ“ Transcription Automatique** : Conversion de la parole en texte via IA
- **ğŸ§  Analyse Ã‰motionnelle** : DÃ©tection automatique de l'ambiance du rÃªve
- **ğŸ¨ GÃ©nÃ©ration d'Images** : CrÃ©ation d'images basÃ©es sur le contenu et l'Ã©motion du rÃªve
- **ğŸ“š Historique Personnel** : Stockage et consultation de tous vos rÃªves
- **ğŸ¯ Interface Moderne** : Design responsive avec animations fluides
- **Authentification** : SystÃ¨me de connexion sÃ©curisÃ©

## ğŸš€ Installation

### PrÃ©requis

- Node.js (version 16 ou supÃ©rieure)
- npm ou yarn

### Ã‰tapes d'installation

1. **Cloner le projet**
   ```bash
   git clone <url-du-repo>
   cd dream-synthesizer
   ```

2. **Installer les dÃ©pendances**
   ```bash
   npm install
   ```

3. **Configuration des APIs de transcription**

   ### Option A : Hugging Face API (RecommandÃ© - Gratuit)
   
   **Guide rapide :**
   1. Allez sur [Hugging Face](https://huggingface.co/) et crÃ©ez un compte gratuit
   2. Allez dans Settings > Access Tokens
   3. CrÃ©ez un nouveau token avec le rÃ´le "Read"
   4. Copiez le token qui commence par `hf_`
   5. Collez-le dans le fichier `.env` :
   ```bash
   cp .env.example .env
   ```
   - Ajoutez votre token dans le fichier `.env` :
   ```
   REACT_APP_HUGGING_FACE_TOKEN=hf_votre_token_ici
   REACT_APP_DEMO_MODE=false
   ```
   
   **Guide dÃ©taillÃ© :** Voir [HUGGING_FACE_SETUP.md](./HUGGING_FACE_SETUP.md)

   ### Option B : Web Speech API (Gratuit, intÃ©grÃ© au navigateur)
   
   Aucune configuration nÃ©cessaire, fonctionne automatiquement dans Chrome/Edge.

   ### Option C : Mode DÃ©mo (Pour les tests)
   
   Laissez `REACT_APP_DEMO_MODE=true` dans le fichier `.env` pour utiliser des transcriptions simulÃ©es.

4. **Lancer l'application**
   ```bash
   npm start
   ```

4. **Ouvrir dans le navigateur**
   ```
   http://localhost:3000
   ```

## ğŸ› ï¸ Technologies UtilisÃ©es

- **React 18** - Framework frontend
- **TypeScript** - Typage statique
- **Material-UI** - Composants UI modernes
- **Framer Motion** - Animations fluides
- **React Router** - Navigation
- **Lucide React** - IcÃ´nes modernes

## ğŸ“± Utilisation

### 1. Enregistrer un RÃªve

1. Cliquez sur "Choisir un fichier audio"
2. SÃ©lectionnez votre fichier audio (.wav ou .mp3)
3. L'application va automatiquement :
   - Transcrire votre audio
   - Analyser l'Ã©motion
   - GÃ©nÃ©rer une image
4. Cliquez sur "Sauvegarder le rÃªve" pour le conserver

### 2. Consulter l'Historique

1. Naviguez vers "Historique" dans le menu
2. Visualisez tous vos rÃªves enregistrÃ©s
3. Cliquez sur une carte pour voir les dÃ©tails
4. Supprimez les rÃªves indÃ©sirables

## ğŸ¨ Design

L'application utilise un design moderne avec :
- **ThÃ¨me sombre** Ã©lÃ©gant
- **Gradients colorÃ©s** pour les accents
- **Animations fluides** avec Framer Motion
- **Interface responsive** pour tous les Ã©crans
- **IcÃ´nes modernes** de Lucide React

## ğŸ”§ Configuration

### Variables d'environnement

CrÃ©ez un fichier `.env` Ã  la racine du projet :

```env
REACT_APP_API_URL=your_api_url_here
```

### Personnalisation du thÃ¨me

Modifiez le thÃ¨me dans `src/App.tsx` pour changer les couleurs et le style.

## ğŸ“Š APIs UtilisÃ©es

### APIs MockÃ©es (DÃ©mo)

L'application utilise actuellement des APIs mockÃ©es pour la dÃ©monstration :

- **Transcription Audio** : Simulation avec dÃ©lais rÃ©alistes
- **Analyse Ã‰motionnelle** : DÃ©tection d'Ã©motions (joyeux, stressant, neutre, etc.)
- **GÃ©nÃ©ration d'Images** : Images placeholder via Picsum Photos

### IntÃ©gration d'APIs RÃ©elles

Pour utiliser des APIs rÃ©elles, modifiez `src/services/dreamService.ts` :

```typescript
// Exemple avec OpenAI Whisper pour la transcription
const transcriptionResponse = await fetch('/api/transcribe', {
  method: 'POST',
  body: formData
});

// Exemple avec OpenAI GPT pour l'analyse d'Ã©motion
const emotionResponse = await fetch('/api/analyze-emotion', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ text: transcription })
});

// Exemple avec DALL-E pour la gÃ©nÃ©ration d'image
const imageResponse = await fetch('/api/generate-image', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ prompt, emotion })
});
```

## ğŸ§ª Tests

```bash
# Lancer les tests
npm test

# Lancer les tests en mode watch
npm test -- --watch

# GÃ©nÃ©rer un rapport de couverture
npm test -- --coverage
```

## ğŸ“¦ Build de Production

```bash
# Construire l'application
npm run build

# PrÃ©visualiser le build
npm run preview
```

## ğŸš€ DÃ©ploiement

### Vercel (RecommandÃ©)

1. Connectez votre repo GitHub Ã  Vercel
2. Vercel dÃ©tectera automatiquement React
3. DÃ©ployez en un clic

### Netlify

1. Construisez l'application : `npm run build`
2. Uploadez le dossier `build` sur Netlify

### Autres plateformes

L'application peut Ãªtre dÃ©ployÃ©e sur n'importe quelle plateforme supportant les applications React statiques.

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©ez une branche feature (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ†˜ Support

Pour toute question ou problÃ¨me :
- Ouvrez une issue sur GitHub
- Contactez l'Ã©quipe de dÃ©veloppement

## ğŸ¯ Roadmap

- [ ] IntÃ©gration d'APIs rÃ©elles (OpenAI, etc.)
- [ ] Support de l'enregistrement audio direct
- [ ] GÃ©nÃ©ration de vidÃ©os courtes
- [ ] Partage social des rÃªves
- [ ] Analyse de tendances Ã©motionnelles
- [ ] Export des donnÃ©es
- [ ] Mode hors ligne
- [ ] Application mobile

---

**DÃ©veloppÃ© avec â¤ï¸ pour transformer vos rÃªves en rÃ©alitÃ© visuelle**
